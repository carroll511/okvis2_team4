/*********************************************************************************
 *  OKVIS - Open Keyframe-based Visual-Inertial SLAM
 *  Copyright (c) 2015, Autonomous Systems Lab / ETH Zurich
 *  Copyright (c) 2020, Smart Robotics Lab / Imperial College London
 *  Copyright (c) 2024, Smart Robotics Lab / Technical University of Munich
 *
 *  Redistribution and use in source and binary forms, with or without
 *  modification, are permitted provided that the following conditions are met:
 *
 *   * Redistributions of source code must retain the above copyright notice,
 *     this list of conditions and the following disclaimer.
 *   * Redistributions in binary form must reproduce the above copyright notice,
 *     this list of conditions and the following disclaimer in the documentation
 *     and/or other materials provided with the distribution.
 *   * Neither the name of Autonomous Systems Lab, ETH Zurich, Smart Robotics Lab,
 *     Imperial College London, Technical University of Munich, nor the names of
 *     its contributors may be used to endorse or promote products derived from
 *     this software without specific prior written permission.
 *
 *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
 *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 *     IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 *  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
 *  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 *  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
 *  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
 *  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
 *  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
 *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
 *  POSSIBILITY OF SUCH DAMAGE.
 *********************************************************************************/

/**
 * @file LightGlueMatcher.cpp
 * @brief LightGlue feature matcher implementation
 */

#include <okvis/LightGlueMatcher.hpp>
#include <okvis/assert_macros.hpp>
#include <glog/logging.h>
#include <algorithm>
#include <cmath>

#ifdef OKVIS_USE_LIGHTGLUE
#include <onnxruntime_cxx_api.h>
#endif

namespace okvis {

#ifdef OKVIS_USE_LIGHTGLUE

LightGlueMatcher::LightGlueMatcher(const std::string& model_path,
                                    float match_threshold,
                                    bool use_gpu)
    : initialized_(false),
      match_threshold_(match_threshold),
      use_gpu_(use_gpu),
      env_(ORT_LOGGING_LEVEL_WARNING, "LightGlue") {
  
  try {
    // Configure session options
    if (use_gpu_) {
      OrtCUDAProviderOptions cuda_options{};
      cuda_options.device_id = 0;
      session_options_.AppendExecutionProvider_CUDA(cuda_options);
    }
    session_options_.SetGraphOptimizationLevel(GraphOptimizationLevel::ORT_ENABLE_ALL);
    session_options_.SetIntraOpNumThreads(1);
    session_options_.SetInterOpNumThreads(1);

    // Create session
    session_ = std::make_unique<Ort::Session>(env_, model_path.c_str(), session_options_);

    // Get input/output names
    Ort::AllocatorWithDefaultOptions allocator;
    size_t num_input_nodes = session_->GetInputCount();
    size_t num_output_nodes = session_->GetOutputCount();

    if (num_input_nodes < 4 || num_output_nodes < 2) {
      LOG(ERROR) << "LightGlue model should have at least 4 inputs and 2 outputs";
      return;
    }

    // Get input names (typically: kpts0, desc0, kpts1, desc1)
    for (size_t i = 0; i < num_input_nodes; ++i) {
      auto input_name = session_->GetInputNameAllocated(i, allocator);
      input_names_.push_back(input_name.get());
    }

    // Get output names (typically: matches0, matches1, mscores0, mscores1)
    for (size_t i = 0; i < num_output_nodes; ++i) {
      auto output_name = session_->GetOutputNameAllocated(i, allocator);
      output_names_.push_back(output_name.get());
    }

    initialized_ = true;
    LOG(INFO) << "LightGlue matcher initialized from: " << model_path;
  } catch (const std::exception& e) {
    LOG(ERROR) << "Failed to initialize LightGlue matcher: " << e.what();
    initialized_ = false;
  }
}

LightGlueMatcher::~LightGlueMatcher() {
  // ONNX Runtime handles cleanup automatically
}

bool LightGlueMatcher::match(const std::vector<cv::KeyPoint>& keypoints0,
                             const cv::Mat& descriptors0,
                             const std::vector<cv::KeyPoint>& keypoints1,
                             const cv::Mat& descriptors1,
                             std::vector<Match>& matches) {
  if (!initialized_) {
    LOG(ERROR) << "LightGlue matcher not initialized";
    return false;
  }

  if (keypoints0.empty() || keypoints1.empty() ||
      descriptors0.empty() || descriptors1.empty()) {
    matches.clear();
    return true; // No matches, but not an error
  }

  // Prepare inputs
  std::vector<float> kpts0_tensor, desc0_tensor;
  std::vector<float> kpts1_tensor, desc1_tensor;
  prepareInputs(keypoints0, descriptors0, keypoints1, descriptors1,
                kpts0_tensor, desc0_tensor, kpts1_tensor, desc1_tensor);

  // Create input tensors
  Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(
      OrtArenaAllocator, OrtMemTypeDefault);

  int num_kpts0 = static_cast<int>(keypoints0.size());
  int num_kpts1 = static_cast<int>(keypoints1.size());

  std::vector<int64_t> kpts0_shape = {1, num_kpts0, 2};
  std::vector<int64_t> desc0_shape = {1, num_kpts0, 256};
  std::vector<int64_t> kpts1_shape = {1, num_kpts1, 2};
  std::vector<int64_t> desc1_shape = {1, num_kpts1, 256};

  Ort::Value kpts0_tensor_ort = Ort::Value::CreateTensor<float>(
      memory_info, kpts0_tensor.data(), kpts0_tensor.size(),
      kpts0_shape.data(), kpts0_shape.size());
  
  Ort::Value desc0_tensor_ort = Ort::Value::CreateTensor<float>(
      memory_info, desc0_tensor.data(), desc0_tensor.size(),
      desc0_shape.data(), desc0_shape.size());
  
  Ort::Value kpts1_tensor_ort = Ort::Value::CreateTensor<float>(
      memory_info, kpts1_tensor.data(), kpts1_tensor.size(),
      kpts1_shape.data(), kpts1_shape.size());
  
  Ort::Value desc1_tensor_ort = Ort::Value::CreateTensor<float>(
      memory_info, desc1_tensor.data(), desc1_tensor.size(),
      desc1_shape.data(), desc1_shape.size());

  std::vector<Ort::Value> input_tensors = {
      std::move(kpts0_tensor_ort),
      std::move(desc0_tensor_ort),
      std::move(kpts1_tensor_ort),
      std::move(desc1_tensor_ort)
  };

  // Run inference
  try {
    auto output_tensors = session_->Run(
        Ort::RunOptions{nullptr},
        input_names_.data(), input_tensors.data(), input_tensors.size(),
        output_names_.data(), output_names_.size());

    // Extract outputs
    // LightGlue outputs: matches0, matches1, mscores0, mscores1
    int64_t* matches0_data = nullptr;
    int64_t* matches1_data = nullptr;
    float* mscores0_data = nullptr;
    int num_matches = 0;

    for (size_t i = 0; i < output_tensors.size(); ++i) {
      auto tensor_info = output_tensors[i].GetTensorTypeAndShapeInfo();
      auto shape = tensor_info.GetShape();
      auto element_type = tensor_info.GetElementType();

      if (element_type == ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64) {
        int64_t* data = output_tensors[i].GetTensorMutableData<int64_t>();
        if (matches0_data == nullptr) {
          matches0_data = data;
          num_matches = static_cast<int>(shape[1]); // [1, N]
        } else {
          matches1_data = data;
        }
      } else if (element_type == ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT) {
        float* data = output_tensors[i].GetTensorMutableData<float>();
        if (mscores0_data == nullptr) {
          mscores0_data = data;
        }
      }
    }

    if (!matches0_data || !matches1_data || !mscores0_data) {
      LOG(ERROR) << "Failed to extract LightGlue outputs";
      return false;
    }

    // Postprocess
    postprocessOutput(matches0_data, matches1_data, mscores0_data,
                     num_matches, matches);

    return true;
  } catch (const std::exception& e) {
    LOG(ERROR) << "LightGlue inference failed: " << e.what();
    return false;
  }
}

void LightGlueMatcher::prepareInputs(const std::vector<cv::KeyPoint>& keypoints0,
                                      const cv::Mat& descriptors0,
                                      const std::vector<cv::KeyPoint>& keypoints1,
                                      const cv::Mat& descriptors1,
                                      std::vector<float>& kpts0_tensor,
                                      std::vector<float>& desc0_tensor,
                                      std::vector<float>& kpts1_tensor,
                                      std::vector<float>& desc1_tensor) {
  // Prepare keypoints: normalize to [-1, 1] range
  // Assuming image size is known or we use a standard size
  const float norm_factor = 1.0f / 320.0f; // Normalize by half image size (typical)
  
  kpts0_tensor.resize(keypoints0.size() * 2);
  for (size_t i = 0; i < keypoints0.size(); ++i) {
    kpts0_tensor[i * 2] = (keypoints0[i].pt.x - 320.0f) * norm_factor;
    kpts0_tensor[i * 2 + 1] = (keypoints0[i].pt.y - 240.0f) * norm_factor;
  }

  kpts1_tensor.resize(keypoints1.size() * 2);
  for (size_t i = 0; i < keypoints1.size(); ++i) {
    kpts1_tensor[i * 2] = (keypoints1[i].pt.x - 320.0f) * norm_factor;
    kpts1_tensor[i * 2 + 1] = (keypoints1[i].pt.y - 240.0f) * norm_factor;
  }

  // Prepare descriptors (already normalized from SuperPoint)
  desc0_tensor.resize(keypoints0.size() * 256);
  for (size_t i = 0; i < keypoints0.size(); ++i) {
    const float* desc_ptr = descriptors0.ptr<float>(i);
    std::copy(desc_ptr, desc_ptr + 256, desc0_tensor.begin() + i * 256);
  }

  desc1_tensor.resize(keypoints1.size() * 256);
  for (size_t i = 0; i < keypoints1.size(); ++i) {
    const float* desc_ptr = descriptors1.ptr<float>(i);
    std::copy(desc_ptr, desc_ptr + 256, desc1_tensor.begin() + i * 256);
  }
}

void LightGlueMatcher::postprocessOutput(const int64_t* matches0_data,
                                         const int64_t* matches1_data,
                                         const float* mscores0_data,
                                         int num_matches,
                                         std::vector<Match>& matches) {
  matches.clear();
  matches.reserve(num_matches);

  for (int i = 0; i < num_matches; ++i) {
    int idx0 = static_cast<int>(matches0_data[i]);
    int idx1 = static_cast<int>(matches1_data[i]);
    float confidence = mscores0_data[i];

    // Filter by confidence threshold
    if (idx0 >= 0 && idx1 >= 0 && confidence >= match_threshold_) {
      matches.push_back({idx0, idx1, confidence});
    }
  }

  // Sort by confidence (descending)
  std::sort(matches.begin(), matches.end(),
            [](const Match& a, const Match& b) {
              return a.confidence > b.confidence;
            });
}

#else // OKVIS_USE_LIGHTGLUE not defined

LightGlueMatcher::LightGlueMatcher(const std::string& /*model_path*/,
                                    float /*match_threshold*/,
                                    bool /*use_gpu*/)
    : initialized_(false), match_threshold_(0.2f), use_gpu_(false) {
  LOG(WARNING) << "LightGlue support not compiled. Rebuild with OKVIS_USE_LIGHTGLUE=ON";
}

LightGlueMatcher::~LightGlueMatcher() {}

bool LightGlueMatcher::match(const std::vector<cv::KeyPoint>& /*keypoints0*/,
                             const cv::Mat& /*descriptors0*/,
                             const std::vector<cv::KeyPoint>& /*keypoints1*/,
                             const cv::Mat& /*descriptors1*/,
                             std::vector<Match>& /*matches*/) {
  LOG(ERROR) << "LightGlue support not compiled";
  return false;
}

void LightGlueMatcher::prepareInputs(const std::vector<cv::KeyPoint>& /*keypoints0*/,
                                      const cv::Mat& /*descriptors0*/,
                                      const std::vector<cv::KeyPoint>& /*keypoints1*/,
                                      const cv::Mat& /*descriptors1*/,
                                      std::vector<float>& /*kpts0_tensor*/,
                                      std::vector<float>& /*desc0_tensor*/,
                                      std::vector<float>& /*kpts1_tensor*/,
                                      std::vector<float>& /*desc1_tensor*/) {}

void LightGlueMatcher::postprocessOutput(const int64_t* /*matches0_data*/,
                                         const int64_t* /*matches1_data*/,
                                         const float* /*mscores0_data*/,
                                         int /*num_matches*/,
                                         std::vector<Match>& /*matches*/) {}

#endif // OKVIS_USE_LIGHTGLUE

} // namespace okvis

